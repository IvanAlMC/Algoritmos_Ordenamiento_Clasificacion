{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Carguemos el conjunto de datos y dividámoslo en un conjunto de entrenamiento y un conjunto de prueba, de la siguiente manera:"],"metadata":{"id":"k19Q9ZDg0373"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"w4uQ8v9I0vYa","executionInfo":{"status":"ok","timestamp":1669234842785,"user_tz":300,"elapsed":1579,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}}},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from numpy import genfromtxt\n","\n","dataset = genfromtxt('https://raw.githubusercontent.com/m-mehdi/tutorials/main/boston_housing.csv', delimiter=',')\n","X = dataset[:,:-1]\n","y = dataset[:,-1]\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=0)"]},{"cell_type":"markdown","source":["Ahora, podemos entrenar el modelo de regresión lineal y luego imprimir el puntaje del conjunto de entrenamiento y el puntaje del conjunto de prueba:"],"metadata":{"id":"VcD4WkRZ09q0"}},{"cell_type":"code","source":["lr = LinearRegression().fit(X_train, y_train)\n","\n","print(f\"Puntaje de entrenamiento por Regresion Lineal: {lr.score(X_train, y_train):.2f}\")\n","print(f\"Puntaje de testeo por Regresion Lineal: {lr.score(X_test, y_test):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A70_2WI-1DJS","executionInfo":{"status":"ok","timestamp":1669234845399,"user_tz":300,"elapsed":4,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"e1918219-3e27-420f-c29f-3095ae9e2d81"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Puntaje de entrenamiento por Regresion Lineal: 0.95\n","Puntaje de testeo por Regresion Lineal: 0.61\n"]}]},{"cell_type":"markdown","source":["La comparación del rendimiento del modelo en el conjunto de entrenamiento y el conjunto de prueba revela que el modelo sufre de sobreajuste.\n","\n","CON L2:\n","\n","Para evitar el sobreajuste y controlar la complejidad del modelo, usemos la regresión de cresta (regularización L2) y veamos qué tan bien funciona en el conjunto de datos:"],"metadata":{"id":"P_3mbXYp1Ffx"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","ridge = Ridge(alpha=0.7).fit(X_train, y_train)\n","print(f\"Puntaje de entrenamiento por Regresion Ridge: {ridge.score(X_train, y_train):.2f}\")\n","print(f\"Puntaje de testeo por Regresion Ridge: {ridge.score(X_test, y_test):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pC5goFN_1LM7","executionInfo":{"status":"ok","timestamp":1669234865076,"user_tz":300,"elapsed":282,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"ee641ad1-d777-466d-86b1-8f020058d2ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Puntaje de entrenamiento por Regresion Ridge: 0.90\n","Puntaje de testeo por Regresion Ridge: 0.76\n"]}]},{"cell_type":"markdown","source":["Aunque la puntuación del conjunto de entrenamiento de la regresión de cresta es ligeramente más baja que la puntuación del entrenamiento de regresión lineal, la puntuación del conjunto de prueba de cresta es significativamente más alta que la puntuación del conjunto de prueba de regresión lineal. Estos puntajes confirman que la regresión de crestas reduce la complejidad del modelo, lo que conduce a un modelo menos sobreajustado pero más general."],"metadata":{"id":"rQCMfE651O6b"}},{"cell_type":"markdown","source":["CON L1"],"metadata":{"id":"vlWCMS3Z16gk"}},{"cell_type":"markdown","source":["El parámetro alpha especifica una compensación entre el rendimiento del modelo en el conjunto de entrenamiento y su simplicidad. Por lo tanto, aumentar el alpha (su valor predeterminado es 1,0) simplifica el modelo al reducir los coeficientes.\n","\n","Ahora, apliquemos la regresión de Lasso al conjunto de datos y exploremos los resultados."],"metadata":{"id":"zkBZisPe19e9"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","lasso = Lasso(alpha=1.0).fit(X_train, y_train)\n","print(f\"Puntaje de entrenamiento por Regresion Lasso: {lasso.score(X_train, y_train):.2f}\")\n","print(f\"Puntaje de testeo por Regresion Lasso: {lasso.score(X_test, y_test):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iP3BLKnc2AFr","executionInfo":{"status":"ok","timestamp":1669235019985,"user_tz":300,"elapsed":286,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"295af248-3de3-44ef-e6a2-e90e8a56b029"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Puntaje de entrenamiento por Regresion Lasso: 0.29\n","Puntaje de testeo por Regresion Lasso: 0.21\n"]}]},{"cell_type":"markdown","source":["Como se muestra, el lasso tiene un rendimiento bastante decepcionante y es una señal de falta de adecuación. El modelo de lazo no funciona bien porque la mayoría de los coeficientes se han vuelto exactamente cero. Si queremos saber el número exacto de características que se han utilizado en el modelo, podemos utilizar el siguiente código:"],"metadata":{"id":"IjQmu5zy2PTr"}},{"cell_type":"code","source":["print(f\"NUmero de funciones: {sum(lasso.coef_ != 0)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uI81z7pQ2Utu","executionInfo":{"status":"ok","timestamp":1669235066246,"user_tz":300,"elapsed":815,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"d65fed40-f25d-4520-dd6d-61915a967596"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["NUmero de funciones: 4\n"]}]},{"cell_type":"markdown","source":["Esto significa que solo 4 de las 104 funciones del conjunto de entrenamiento se usan en el modelo de regresión de lasso, mientras que el resto se ignora.\n","\n","Ajustemos alpha para reducir el ajuste insuficiente disminuyendo su valor a 0.01:"],"metadata":{"id":"FMHOyLYv2VmK"}},{"cell_type":"code","source":["lasso = Lasso(alpha=0.01).fit(X_train, y_train)\n","print(\"Puntaje de entrenamiento por Regresion Lasso: {:.2f}\".format(lasso.score(X_train, y_train)))\n","print(\"Puntaje de testeo por Regresion Lasso: {:.2f}\".format(lasso.score(X_test, y_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grmkq7iD2hhH","executionInfo":{"status":"ok","timestamp":1669235108301,"user_tz":300,"elapsed":232,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"46dbbb58-ecf5-4fb2-8f89-91dfe4b7e9a2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Puntaje de entrenamiento por Regresion Lasso: 0.90\n","Puntaje de testeo por Regresion Lasso: 0.77\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.690e+01, tolerance: 3.233e+00\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]}]},{"cell_type":"code","source":["print(f\"Numero de funciones: {sum(lasso.coef_ != 0)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zx0qSNdh2pXt","executionInfo":{"status":"ok","timestamp":1669235148666,"user_tz":300,"elapsed":264,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"a7310a59-7748-4f48-f923-5aa92aea99f5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Numero de funciones: 32\n"]}]},{"cell_type":"markdown","source":["Volver a ejecutar el código a continuación muestra que al disminuir alpha, el modelo Lasso usa 32 de las 104 funciones:"],"metadata":{"id":"oD8rhv3o2rfs"}},{"cell_type":"markdown","source":["Aunque podemos reducir alpha aún más, parece que su valor óptimo es 0.01."],"metadata":{"id":"XQjullNi2v3-"}},{"cell_type":"markdown","source":[" Usando la técnica que vamos a utilizar es la ElasticNet:"],"metadata":{"id":"9e6l2Nne3wc_"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01).fit(X_train, y_train)\n","print(f\"Puntaje de entrenamiento para el modelo Elastic Net: {elastic_net.score(X_train, y_train):.2f}\")\n","print(f\"Puntaje de testeo para el modelo Elastic Net: {elastic_net.score(X_test, y_test):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYccgmD226zO","executionInfo":{"status":"ok","timestamp":1669235146064,"user_tz":300,"elapsed":766,"user":{"displayName":"DIEGO MAURICIO SIERRA MAESTRE","userId":"07676920269543777778"}},"outputId":"40cf9ea4-2fe3-4887-8111-a1fe422db80e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Puntaje de entrenamiento para el modelo Elastic Net: 0.84\n","Puntaje de testeo para el modelo Elastic Net: 0.70\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.474e+02, tolerance: 3.233e+00\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]}]}]}